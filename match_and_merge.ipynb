{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preloading all schemas and categories\n",
    "all_schemas={}\n",
    "all_categories={}\n",
    "with open(\"final_schema.txt\") as ip_file:\n",
    "    for line in ip_file.readlines():\n",
    "        json_obj=json.loads(line)\n",
    "        all_schemas[json_obj[\"filename\"]]=json_obj[\"schema\"]\n",
    "        all_categories[json_obj[\"filename\"]]=json_obj[\"categories\"]\n",
    "        \n",
    "#preloading the candidate keys\n",
    "with open(\"Candidate_key_dict.txt\",'r') as ip_file:\n",
    "    cand_key=json.load(ip_file)\n",
    "\n",
    "#preloading column and category similarity values of tables\n",
    "with open(\"cos_similarity.txt\",'r') as ip_file:\n",
    "    json_object=json.load(ip_file)\n",
    "col_sim = json_object[\"column_similarity\"]\n",
    "cat_sim = json_object[\"category_similarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all functions needed to generate ontologies\n",
    "def get_synonyms(word):\n",
    "    meanings=set()\n",
    "    for synset in wordnet.synsets(word,pos=wordnet.NOUN):\n",
    "        for lemma in synset.lemmas():\n",
    "            meanings.add(lemma.name())\n",
    "    for synset in wordnet.synsets(word,pos=wordnet.NOUN):\n",
    "        for hypernym in synset.hypernyms():\n",
    "            meanings.add(hypernym.lemma_names()[0])\n",
    "    meanings.add(word)\n",
    "    return list(meanings)\n",
    "\n",
    "def generate_list_ontology(list1):\n",
    "    ontology={}\n",
    "    for word in list1:\n",
    "        ontology[word]=get_synonyms(word)\n",
    "    return ontology\n",
    "\n",
    "def generate_schema_ontology(input_schema):\n",
    "    ontology={}\n",
    "    for col in input_schema:\n",
    "        ontology[col]=get_synonyms(col)\n",
    "    return ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to generate cos similarity between two lists\n",
    "def cos_sim(list1, list2):\n",
    "    terms = set(list1).union(list2)\n",
    "    intersect = set(list1) & set(list2)\n",
    "    others = (set(list1)-intersect).union(set(list2)-intersect)\n",
    "    product=0\n",
    "    for word in terms:\n",
    "        if word in intersect:\n",
    "            product+=1\n",
    "    l1mag = math.sqrt(len(list1))\n",
    "    l2mag = math.sqrt(len(list2))\n",
    "    if len(list1)==0 or len(list2)==0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return product / (l1mag * l2mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if input has only schema(columns and their dataypes)\n",
    "def col_only_list(input_schema,input_sch_onto):\n",
    "    possible_tables={}\n",
    "    for file in all_schemas:\n",
    "        schema=all_schemas[file]\n",
    "        for col,d_type in schema.items():\n",
    "            if (col in input_schema) and (input_schema[col]==d_type):\n",
    "                if file in possible_tables:\n",
    "                    possible_tables[file].append(col)\n",
    "                else:\n",
    "                    possible_tables[file]=list(col)\n",
    "            else:\n",
    "                for a in input_sch_onto:\n",
    "                    if (col in input_sch_onto[a]) and (input_schema[a]==d_type):\n",
    "                        if file in possible_tables:\n",
    "                            possible_tables[file].append(a)\n",
    "                        else:\n",
    "                            possible_tables[file]=list(a)\n",
    "    return possible_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if input has categories as well as schema(columns and their dataypes)\n",
    "# we consider it a match under the assumption that at least 75% category match exists\n",
    "def cat_and_col_list(input_categories,input_cat_onto,input_schema,input_sch_onto):\n",
    "    possible_tables={}\n",
    "    for file in all_categories:\n",
    "        cat_list=[]\n",
    "        category=all_categories[file]\n",
    "        for cat in category:\n",
    "            if cat in input_categories:\n",
    "                cat_list.append(cat)\n",
    "            else:\n",
    "                for cat1 in input_cat_onto:\n",
    "                    if cat in input_cat_onto[cat1]:\n",
    "                        cat_list.append(cat1)\n",
    "        cos_val=cos_sim(cat_list,input_categories)\n",
    "        if cos_val > 0.75 :\n",
    "            schema=all_schemas[file]\n",
    "            for col,d_type in schema.items():\n",
    "                if (col in input_schema) and (input_schema[col]==d_type):\n",
    "                    if file in possible_tables:\n",
    "                        possible_tables[file].append(col)\n",
    "                    else:\n",
    "                        possible_tables[file]=list(col)\n",
    "                else:\n",
    "                    for a in input_sch_onto:\n",
    "                        if (col in input_sch_onto[a]) and (input_schema[a]==d_type):\n",
    "                            if file in possible_tables:\n",
    "                                possible_tables[file].append(a)\n",
    "                            else:\n",
    "                                possible_tables[file]=list(a)\n",
    "    return possible_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the given input file names , find the columns that match if any.\n",
    "#If no colmns match , then don't do anything.\n",
    "#If columns match , then check if the columns are present in the list of candidate keys.\n",
    "#If not present in list of candidate keys , just check data.\n",
    "#If present in list of candidate keys and data of those columns match , append the others columns to any of the table to extend the table schema.\n",
    "#If present in list of candidate keys but data dont match , then increse volume by adding the rows to one of the table , but will create a lot of NULL values. Undesirable.\n",
    "#If all the columns match , then to each table just add another column with the table name and append the two tables.\n",
    "\n",
    "def merge(fname1,fname2):\n",
    "    matching_columns = {}  #resultant list containing the matching columns.\n",
    "    #getting schema for tables.\n",
    "    f1 = all_schemas[fname1]\n",
    "    f2 = all_schemas[fname2]\n",
    "    #Retrieving the column names and generating the ontologies for one of the tables columns\n",
    "    f1_cols = list(f1)\n",
    "    f1_onto = generate_list_ontology(f1_cols)\n",
    "    #finding columns that match.     \n",
    "    for col , d_type in f2.items():\n",
    "        if(col in f1_cols):\n",
    "            matching_columns[col] = col\n",
    "        else:\n",
    "            for col_t1 in f1_onto:\n",
    "                if(col in f1_onto[col_t1]):\n",
    "                    matching_columns[col_t1] = col\n",
    "                    break\n",
    "    #Now the varaible matching_columns contains a list of names of columns that match between the two tables.\n",
    "    print(matching_columns)\n",
    "    t1 = cand_key[fname1]\n",
    "    t2 = cand_key[fname2]\n",
    "    for key , value in matching_columns.items():\n",
    "        if(key in t1 or value in t2):\n",
    "            pass\n",
    "        else:\n",
    "            matching_columns.pop(key)\n",
    "    merge_tables(fname1,fname2,matching_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tables(fname1,fname2,cols):\n",
    "    t1 = pd.read_csv(fname1)\n",
    "    t2 = pd.read_csv(fname2)\n",
    "    l=len(cols)\n",
    "    if l!=0:\n",
    "        for name1,name2 in cols.items():\n",
    "            t2.rename(columns = {name2:name1},inplace=True)\n",
    "    t3=t1.merge(t2,how='outer')\n",
    "    print(fname1+' and '+fname2+' gives : ')\n",
    "    display(t3)\n",
    "    return(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_possible_matches():\n",
    "    with open(\"input.txt\",'r') as ip_file:\n",
    "        json_object=json.load(ip_file)\n",
    "    input_schema=json_object[\"schema\"]\n",
    "    input_sch_onto=generate_schema_ontology(input_schema)\n",
    "    if \"categories\" in json_object:\n",
    "        input_categories=json_object[\"categories\"]\n",
    "        input_cat_onto=generate_list_ontology(input_categories)\n",
    "        possible_tables=cat_and_col_list(input_categories,input_cat_onto,input_schema,input_sch_onto)\n",
    "    else:\n",
    "        possible_tables=col_only_list(input_schema,input_sch_onto)\n",
    "    matching_tables=[]\n",
    "    for i in possible_tables:\n",
    "        cos_val=cos_sim(possible_tables[i],list(input_schema))\n",
    "        if cos_val>0.50:\n",
    "            matching_tables.append(i)\n",
    "    return matching_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches():\n",
    "    matching_tables=check_possible_matches()\n",
    "    op_str1='output_folder/'\n",
    "    op_str2='.txt'\n",
    "    f=open(\"matches.txt\",'w')\n",
    "    x=len(matching_tables)\n",
    "    if x==0:\n",
    "        print(\"NO MATCHES FOUND\",file=f)\n",
    "    elif x==1:\n",
    "        print(matching_tables[0]+'\\n',file=f)\n",
    "    else:\n",
    "        ctr=0\n",
    "        for i in range(x):\n",
    "            for j in range(1,x):\n",
    "                a=matching_tables[i]+' : '+matching_tables[j]\n",
    "                b=matching_tables[j]+' : '+matching_tables[i]\n",
    "                if (a in cat_sim):\n",
    "                    if cat_sim[a]>=.75 and col_sim[a]>=0.25:\n",
    "                        res=merge(matching_tables[i],matching_tables[j])\n",
    "                        ctr+=1\n",
    "                        op_string=op_str1+str(ctr)+op_str2\n",
    "                        res.to_csv(op_string,sep=',', index=False)\n",
    "                        print(matching_tables[i]+' and '+matching_tables[j]+'\\n',file=f)\n",
    "                elif (b in cat_sim):\n",
    "                    if cat_sim[b]>=.75 and col_sim[b]>=0.25:\n",
    "                        res=merge(matching_tables[i],matching_tables[j])\n",
    "                        ctr+=1\n",
    "                        op_string=op_str1+str(ctr)+op_str2\n",
    "                        res.to_csv(op_string,sep=',', index=False)\n",
    "                        print(matching_tables[i]+' and '+matching_tables[j]+'\\n',file=f)\n",
    "                else:\n",
    "                    pass\n",
    "        for i in matching_tables:\n",
    "            print(i+'\\n',file=f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions=[\"sum\",\"product\",\"power\",\"square root\",\"quotient\",\"mod\",\"subtotal\",\"ceiling\",\"floor\",\"int\",\"trunc\",\"count\",\"countif\",\"counta\",\"max\",\"min\",\"average\",\"averagea\",\"median\",\"mode\",\"stdev\",\"var\",\"frequency\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
